{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FHE-based Aging Pace Estimation by Horaizon27 team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from concrete import fhe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path(\"data\")\n",
    "DUNEDIN_PACE_DATA_PATH = DATA_FOLDER / \"dunedin_pace_data.json\"\n",
    "BETA_VALUES_PATH = DATA_FOLDER / \"GSE40279_average_beta.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dunedin model params/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dunedin_pace_data = json.loads(open(DUNEDIN_PACE_DATA_PATH).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing beta values\n",
    "1) Load beta values (you need to download GSE40279 dataset to \"data\" folder)\n",
    "2) Add missing probes data (using mean data from dunedin model)\n",
    "2) Filter only needed probes (recommended 20k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_values = pd.read_csv(BETA_VALUES_PATH, delimiter=\"\\t\", index_col=0)\n",
    "\n",
    "probes_mean = {\n",
    "    dunedin_pace_data['normalization_probes'][i]: dunedin_pace_data['normalization_means'][i]\n",
    "    for i in range(len(dunedin_pace_data['normalization_probes']))\n",
    "}\n",
    "\n",
    "missing_probes = [_ for _ in dunedin_pace_data['normalization_probes'] if _ not in beta_values.index]\n",
    "missing_probes_data = [[probes_mean[_]] * len(beta_values.columns) for _ in missing_probes]\n",
    "missing_betas = pd.DataFrame(missing_probes_data, index=missing_probes, columns=beta_values.columns)\n",
    "filtered_beta_values = pd.concat([beta_values, missing_betas]).loc[dunedin_pace_data['normalization_probes']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DunedinPACE python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DunedinPACE():\n",
    "    def _get_pace(self, x):\n",
    "        return np.dot(x, self.weights) + self.intercept\n",
    "\n",
    "    def __init__(self, name, features, base_features, reference_values, weights, intercept):\n",
    "        self.name = name\n",
    "        self.features = features\n",
    "        self.reference_values = reference_values\n",
    "        self.weights = weights\n",
    "        self.intercept = intercept\n",
    "        base_features_indices = [features.index(item) for item in base_features]\n",
    "        self.base_features_indices = base_features_indices\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # check input data\n",
    "        if x.ndim > 1 or len(x) != len(self.features):\n",
    "            raise ValueError(f\"Expected 1D array with {len(self.features)} probes, got shape {x.shape}\")\n",
    "        \n",
    "        # apply normalization\n",
    "        x = self.preprocess(x)\n",
    "        \n",
    "        # return calculated pace\n",
    "        return self._get_pace(x)\n",
    "    \n",
    "    def preprocess(self, x):\n",
    "        sorted_gold_standard = np.sort(self.reference_values)\n",
    "        indexes = np.argsort(x)\n",
    "        x_normalized = np.zeros(x.size, dtype=np.float64)\n",
    "        x_normalized[indexes] = sorted_gold_standard\n",
    "        return x_normalized[self.base_features_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dunedin_model = DunedinPACE(\n",
    "    name=\"dunedin_pace\",\n",
    "    features=dunedin_pace_data['normalization_probes'],\n",
    "    base_features=dunedin_pace_data['probes'],\n",
    "    reference_values = dunedin_pace_data['normalization_means'],\n",
    "    weights=dunedin_pace_data['weights'],\n",
    "    intercept=dunedin_pace_data['intercept']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dunnedin FHE version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FHEDunedinPACE():\n",
    "    def __init__(self, name, features, base_features, reference_values, weights, intercept):\n",
    "        self.name = name\n",
    "        self.scale = 100000\n",
    "        self.features = features\n",
    "        self.reference_values = reference_values\n",
    "        self.sorted_gold_standard_int = (np.sort(self.reference_values) * self.scale).astype(np.int64)\n",
    "        self.weights = np.array(weights)\n",
    "        self.weights_int = (self.weights * self.scale).astype(np.int64)\n",
    "        self.intercept = intercept\n",
    "        self.intercept_int = int(self.intercept * (self.scale ** 2))\n",
    "        base_features_indices = [features.index(item) for item in base_features]\n",
    "        self.base_features_indices = base_features_indices\n",
    "        self.circuit = self._create_circuit()\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def _get_pace(self, x, weights, intercept):\n",
    "        return np.dot(x, weights) + intercept # intercept = -19498585554\n",
    "\n",
    "    def _create_circuit(self, inputset_size=200):\n",
    "        fhe_compiler = fhe.Compiler(\n",
    "            function=self._get_pace,\n",
    "            parameter_encryption_statuses={\n",
    "                \"x\": \"encrypted\",\n",
    "                \"weights\": \"clear\",\n",
    "                \"intercept\": \"clear\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        inputset_for_compiler = [\n",
    "            (\n",
    "                np.random.permutation(self.sorted_gold_standard_int[self.base_features_indices]),\n",
    "                self.weights_int,\n",
    "                self.intercept_int\n",
    "            )\n",
    "            for _ in range(inputset_size)\n",
    "        ]\n",
    "        circuit = fhe_compiler.compile(inputset_for_compiler)\n",
    "        return circuit\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # check input data\n",
    "        if x.ndim > 1 or len(x) != len(self.features):\n",
    "            raise ValueError(f\"Expected 1D array with {len(self.features)} probes, got shape {x.shape}\")\n",
    "        \n",
    "        # apply normalization\n",
    "        x = self.preprocess(x)\n",
    "\n",
    "        # calculate pace with fhe circuit using encrypted data\n",
    "        pace = self.circuit.encrypt_run_decrypt(x, self.weights_int, self.intercept_int)\n",
    "\n",
    "        # convert pace to float\n",
    "        return self.postprocess(pace)\n",
    "    \n",
    "    def preprocess(self, x):\n",
    "        indexes = np.argsort(x)\n",
    "        x_normalized = np.zeros(x.size, dtype=np.int64)\n",
    "        x_normalized[indexes] = self.sorted_gold_standard_int\n",
    "        return x_normalized[self.base_features_indices]\n",
    "    \n",
    "    def postprocess(self, pace):\n",
    "        return pace / (self.scale ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhe_dunedin_model = FHEDunedinPACE(\n",
    "    name = \"fhe_dunedin_pace\",\n",
    "    features=dunedin_pace_data['normalization_probes'],\n",
    "    base_features=dunedin_pace_data['probes'],\n",
    "    reference_values = dunedin_pace_data['normalization_means'],\n",
    "    weights=dunedin_pace_data['weights'],\n",
    "    intercept=dunedin_pace_data['intercept']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dunnedin FHE version with high precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FHEDunedinPACEHighPrecision():\n",
    "    def __init__(self, name, features, base_features, reference_values, weights, intercept):\n",
    "        self.name = name\n",
    "        self.scale = 10000\n",
    "        self.features = features\n",
    "        self.reference_values = reference_values\n",
    "        self.sorted_gold_standard = np.sort(self.reference_values)\n",
    "        self.sorted_gold_standard_int = (self.sorted_gold_standard * self.scale).astype(np.int64)\n",
    "        self.weights = np.array(weights)\n",
    "        weights_high, weights_low = self._split_float_array(self.weights)\n",
    "        self.weights_high = weights_high\n",
    "        self.weights_low = weights_low\n",
    "        self.intercept = intercept\n",
    "        base_features_indices = [features.index(item) for item in base_features]\n",
    "        self.base_features_indices = base_features_indices\n",
    "        self.circuit = self._create_circuit()\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def _get_pace(self, x, weights):\n",
    "        return np.dot(x, weights)\n",
    "\n",
    "    def _create_circuit(self, inputset_size=200):\n",
    "        fhe_compiler = fhe.Compiler(\n",
    "            function=self._get_pace,\n",
    "            parameter_encryption_statuses={\n",
    "                \"x\": \"encrypted\",\n",
    "                \"weights\": \"clear\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        inputset_for_compiler = [\n",
    "            (\n",
    "                np.random.randint(0, self.scale * 10, size=len(self.weights), dtype=np.int64),\n",
    "                self.weights_high + self.weights_low,\n",
    "            )\n",
    "            for _ in range(inputset_size)\n",
    "        ]\n",
    "\n",
    "        circuit = fhe_compiler.compile(inputset_for_compiler)\n",
    "        return circuit\n",
    "\n",
    "    def _split_float_array(self, x):\n",
    "        x = (np.array(x) * (self.scale ** 2)).astype(np.int64)\n",
    "        x_high = x // self.scale\n",
    "        x_low = x % self.scale\n",
    "        return (x_high, x_low)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # check input data\n",
    "        if x.ndim > 1 or len(x) != len(self.features):\n",
    "            raise ValueError(f\"Expected 1D array with {len(self.features)} probes, got shape {x.shape}\")\n",
    "        \n",
    "        # apply normalization\n",
    "        x = self.preprocess(x)\n",
    "\n",
    "        # split betas data on two parts to implement high precision float multiplication\n",
    "        x_high, x_low = self._split_float_array(x)\n",
    "        \n",
    "        # calculate pace by parts\n",
    "        pace_1 = self.circuit.encrypt_run_decrypt(x_high, self.weights_high)\n",
    "        pace_2 = self.circuit.encrypt_run_decrypt(x_high, self.weights_low)\n",
    "        pace_3 = self.circuit.encrypt_run_decrypt(x_low, self.weights_high)\n",
    "        pace_4 = self.circuit.encrypt_run_decrypt(x_low, self.weights_low)\n",
    "\n",
    "        pace = pace_1  + (pace_2 + pace_3) / self.scale + pace_4 / (self.scale ** 2)\n",
    "\n",
    "        # convert pace to float and add intercept\n",
    "        return self.postprocess(pace)\n",
    "    \n",
    "    def preprocess(self, x):\n",
    "        indexes = np.argsort(x)\n",
    "        x_normalized = np.zeros(x.size, dtype=np.float64)\n",
    "        x_normalized[indexes] = self.sorted_gold_standard\n",
    "        return x_normalized[self.base_features_indices]\n",
    "    \n",
    "    def postprocess(self, pace):\n",
    "        return pace / (self.scale ** 2) + self.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhe_precision_dunedin_model = FHEDunedinPACEHighPrecision(\n",
    "    name=\"fhe_high_precision_dunedin_pace\",\n",
    "    features=dunedin_pace_data['normalization_probes'],\n",
    "    base_features=dunedin_pace_data['probes'],\n",
    "    reference_values = dunedin_pace_data['normalization_means'],\n",
    "    weights=dunedin_pace_data['weights'],\n",
    "    intercept=dunedin_pace_data['intercept']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [\n",
    "    dunedin_model, fhe_dunedin_model, fhe_precision_dunedin_model\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PACE calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pace(model, dataset):\n",
    "    start_time = time.time()\n",
    "    pace = [\n",
    "        model(dataset[column_name].values)\n",
    "        for column_name in dataset.columns\n",
    "    ]\n",
    "    end_time = time.time()\n",
    "    avg_inference_time = (end_time - start_time) / dataset.columns.size\n",
    "    return (np.array(pace), avg_inference_time)\n",
    "\n",
    "def get_mae(x, y):\n",
    "    return np.mean(np.abs(x - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pace_data = {}\n",
    "inference_time = []\n",
    "for model in models_list:\n",
    "    pace, avg_inference_time = get_pace(model, filtered_beta_values)\n",
    "    pace_data[model.name] = pace\n",
    "    inference_time.append(avg_inference_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pace = pace_data[\"dunedin_pace\"]\n",
    "mae_list = []\n",
    "\n",
    "for model in models_list:\n",
    "    mae_list.append(get_mae(true_pace, pace_data[model.name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dunedin_pace</th>\n",
       "      <th>fhe_dunedin_pace</th>\n",
       "      <th>fhe_high_precision_dunedin_pace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Avg_inference_time</th>\n",
       "      <td>0.00318715</td>\n",
       "      <td>0.04702486</td>\n",
       "      <td>0.17222939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00019811</td>\n",
       "      <td>0.00000020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    dunedin_pace  fhe_dunedin_pace  \\\n",
       "Avg_inference_time    0.00318715        0.04702486   \n",
       "mae                   0.00000000        0.00019811   \n",
       "\n",
       "                    fhe_high_precision_dunedin_pace  \n",
       "Avg_inference_time                       0.17222939  \n",
       "mae                                      0.00000020  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:.8f}'.format\n",
    "pd.DataFrame(\n",
    "    [inference_time, mae_list],\n",
    "    index=[\"Avg_inference_time\", \"mae\"],\n",
    "    columns=[model.name for model in models_list]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
